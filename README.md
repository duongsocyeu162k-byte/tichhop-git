# ğŸš€ Job Market Analytics (Simplified - JSON-based)

## ğŸ“‹ Tá»•ng quan Dá»± Ã¡n

Dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u thá»‹ trÆ°á»ng viá»‡c lÃ m tá»« 3 nguá»“n khÃ¡c nhau vá»›i kiáº¿n trÃºc Ä‘Æ¡n giáº£n dá»±a trÃªn file JSON.

### ğŸ¯ Má»¥c tiÃªu
- âœ… TÃ­ch há»£p vÃ  lÃ m sáº¡ch dá»¯ liá»‡u tá»« 3 nguá»“n: CareerLink, Joboko, TopCV
- âœ… PhÃ¢n tÃ­ch toÃ n diá»‡n thá»‹ trÆ°á»ng viá»‡c lÃ m táº¡i Viá»‡t Nam
- âœ… Xuáº¥t dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ ra file JSON (khÃ´ng cáº§n database)
- âœ… Cung cáº¥p API vÃ  Dashboard Ä‘á»ƒ truy váº¥n vÃ  visualize dá»¯ liá»‡u

### âœ¨ Äiá»ƒm khÃ¡c biá»‡t phiÃªn báº£n má»›i
- **KhÃ´ng cáº§n PostgreSQL hay MongoDB** - Táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trong file JSON
- **ÄÆ¡n giáº£n hÆ¡n** - Dá»… setup vÃ  cháº¡y
- **Linh hoáº¡t** - Dá»¯ liá»‡u JSON dá»… chia sáº» vÃ  xá»­ lÃ½
- **Nhanh hÆ¡n** - KhÃ´ng cáº§n quáº£n lÃ½ database

## ğŸ“Š Dataset

| Dataset | Nguá»“n | KÃ­ch thÆ°á»›c | MÃ´ táº£ |
|---------|-------|------------|-------|
| `data_careerlink.json` | CareerLink | ~15,772 records | Viá»‡c lÃ m IT táº¡i Viá»‡t Nam |
| `data_joboko.json` | Joboko | ~7,522 records | Viá»‡c lÃ m Ä‘a dáº¡ng táº¡i Viá»‡t Nam |
| `data_topcv.json` | TopCV | ~2,420 records | Viá»‡c lÃ m IT/CNTT táº¡i Viá»‡t Nam |

### Cáº¥u trÃºc Dá»¯ liá»‡u
- **CareerLink**: TÃªn cÃ´ng viá»‡c, TÃªn cÃ´ng ty, Äá»‹a Ä‘iá»ƒm, Má»©c lÆ°Æ¡ng, Kinh nghiá»‡m, MÃ´ táº£, Ká»¹ nÄƒng yÃªu cáº§u
- **Joboko**: TÃªn cÃ´ng viá»‡c, TÃªn cÃ´ng ty, Äá»‹a Ä‘iá»ƒm, Má»©c lÆ°Æ¡ng, Kinh nghiá»‡m, MÃ´ táº£, Ká»¹ nÄƒng yÃªu cáº§u, NgÃ nh nghá»
- **TopCV**: TÃªn cÃ´ng viá»‡c, TÃªn cÃ´ng ty, Äá»‹a Ä‘iá»ƒm, Má»©c lÆ°Æ¡ng, Kinh nghiá»‡m, MÃ´ táº£, Ká»¹ nÄƒng yÃªu cáº§u, Quyá»n lá»£i

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng (Simplified)

```
ğŸ“¥ DATA SOURCES (JSON Files)
â”œâ”€â”€ data/data_careerlink.json
â”œâ”€â”€ data/data_joboko.json
â””â”€â”€ data/data_topcv.json
         â¬‡ï¸
ğŸ”„ ETL PIPELINE (json_export_pipeline.py)
â”œâ”€â”€ 1. Load: DataLoader
â”œâ”€â”€ 2. Clean & Standardize: DataCleaner (LÃ€M TRÆ¯á»šC)
â”œâ”€â”€ 3. Schema Matching: SchemaMatcher (trÃªn cleaned data)
â”œâ”€â”€ 4. Data Matching: DataMatcher (trÃªn cleaned data)
â”œâ”€â”€ 5. Combine: Merge táº¥t cáº£ sources
â””â”€â”€ 6. Export: JSONExporter
         â¬‡ï¸
ğŸ’¾ OUTPUT (JSON Files)
â”œâ”€â”€ output/export-TIMESTAMP.json               (Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½)
â”œâ”€â”€ output/matching_report_TIMESTAMP.json      (Schema & Data Matching)
â””â”€â”€ output/pipeline_summary.json                (TÃ³m táº¯t pipeline)



## ğŸ› ï¸ CÃ´ng nghá»‡ Sá»­ dá»¥ng

### Core Technologies
- **Python 3.8+**: NgÃ´n ngá»¯ chÃ­nh
- **Pandas**: Data manipulation vÃ  analysis
- **NumPy**: Numerical computing
- **Scikit-learn**: Machine learning

### Storage
- **JSON Files**: LÆ°u trá»¯ dá»¯ liá»‡u Ä‘Æ¡n giáº£n, dá»… chia sáº»

### Analytics & Visualization
- **Plotly**: Interactive charts
- **Streamlit**: Web dashboard
- **FastAPI**: REST API
- **Jupyter**: Interactive analysis

### Infrastructure
- **Docker** (optional): Containerization
- **Git**: Version control

## ğŸš€ CÃ i Ä‘áº·t vÃ  Cháº¡y Dá»± Ã¡n

### YÃªu cáº§u Há»‡ thá»‘ng
- Python 3.8+ 
- pip (Python package manager)
- (Optional) Docker & Docker Compose

### CÃ¡ch 1: Cháº¡y trá»±c tiáº¿p (KhuyÃªn dÃ¹ng - ÄÆ¡n giáº£n nháº¥t)

**BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies**

```bash
# Táº¡o virtual environment (khuyÃªn dÃ¹ng)
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install --upgrade pip
pip install -r requirements.txt
```

**BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u**

Äáº£m báº£o cÃ¡c file dá»¯ liá»‡u cÃ³ trong thÆ° má»¥c `data/`:
- `data/data_careerlink.json`
- `data/data_joboko.json`
- `data/data_topcv.json`

**BÆ°á»›c 3: Cháº¡y ETL Pipeline**

```bash
python json_export_pipeline.py
```

Pipeline sáº½ thá»±c hiá»‡n theo thá»© tá»±:
1. âœ… **Load Data**: Äá»c dá»¯ liá»‡u tá»« 3 nguá»“n JSON (CareerLink, Joboko, TopCV)
2. âœ… **Clean & Standardize** â¬…ï¸ **LÃ€M TRÆ¯á»šC**: LÃ m sáº¡ch vÃ  chuáº©n hÃ³a dá»¯ liá»‡u
   - Normalize text, locations, salaries
   - Extract structured data (experience, skills)
   - Standardize column names
   - Táº¡o standard columns (job_title_clean, company_name, location_clean, etc.)
3. âœ… **Schema Matching**: PhÃ¢n tÃ­ch tÆ°Æ¡ng thÃ­ch schema giá»¯a cÃ¡c nguá»“n (trÃªn cleaned data)
   - Detect schema Ä‘Ã£ standardized
   - So sÃ¡nh schema giá»¯a cÃ¡c nguá»“n
   - Táº¡o unified schema
   - Validate compatibility
4. âœ… **Data Matching**: TÃ¬m duplicates vÃ  entity resolution (trÃªn cleaned data)
   - Duplicate detection (chÃ­nh xÃ¡c hÆ¡n vá»›i normalized data)
   - Similarity analysis
   - Entity resolution (companies, job titles)
5. âœ… **Combine**: Káº¿t há»£p dá»¯ liá»‡u tá»« táº¥t cáº£ nguá»“n
6. âœ… **Export**: Xuáº¥t káº¿t quáº£ ra thÆ° má»¥c `output/`:
   - `export-TIMESTAMP.json` - Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
   - `matching_report_TIMESTAMP.json` - Schema & Data Matching results
   - `pipeline_summary.json` - TÃ³m táº¯t pipeline

### CÃ¡ch 2: Cháº¡y vá»›i Docker

**BÆ°á»›c 1: Build vÃ  cháº¡y containers**

```bash
# Cháº¡y pipeline bÃªn ngoÃ i container
python json_export_pipeline.py

# Hoáº·c cháº¡y trong container
docker-compose exec api python json_export_pipeline.py
```

## ğŸ“ Cáº¥u trÃºc ThÆ° má»¥c

```
tichhop-git/
â”œâ”€â”€ data/                           # ğŸ“¥ Dá»¯ liá»‡u nguá»“n (JSON)
â”‚   â”œâ”€â”€ data_careerlink.json
â”‚   â”œâ”€â”€ data_joboko.json
â”‚   â””â”€â”€ data_topcv.json
â”‚
â”œâ”€â”€ output/                         # ğŸ’¾ Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ (JSON)
â”‚   â”œâ”€â”€ export-*.json               # Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch vÃ  standardized
â”‚   â”œâ”€â”€ matching_report_*.json      # Schema & Data Matching results
â”‚   â””â”€â”€ pipeline_summary.json       # TÃ³m táº¯t pipeline
â”‚
â”œâ”€â”€ src/                           # ğŸ“¦ Source code
â”‚   â”œâ”€â”€ etl/                      # ETL modules
â”‚   â”‚   â”œâ”€â”€ data_loader.py        # Load dá»¯ liá»‡u tá»« JSON
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py       # LÃ m sáº¡ch & chuáº©n hÃ³a dá»¯ liá»‡u
â”‚   â”‚   â””â”€â”€ schema_matcher.py     # Schema matching & Data matching
â”‚   â””â”€â”€ analytics/                # Analytics modules
â”‚       â”œâ”€â”€ comprehensive_analyzer.py
â”‚       â”œâ”€â”€ trend_analyzer.py
â”‚       â”œâ”€â”€ salary_predictor.py
â”‚       â””â”€â”€ ...

â”œâ”€â”€ notebooks/                     # ğŸ““ Jupyter notebooks
â”‚   â””â”€â”€ 01_data_exploration.ipynb
â”‚
â”œâ”€â”€ config/                        # âš™ï¸ Configuration files
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ docker/                        # ğŸ³ Docker configurations
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.dashboard
â”‚   â””â”€â”€ Dockerfile.jupyter
â”‚
â”œâ”€â”€ json_export_pipeline.py        # ğŸš€ Main ETL pipeline
â”œâ”€â”€ requirements.txt               # ğŸ“‹ Python dependencies
â”œâ”€â”€ docker-compose.yml             # ğŸ³ Docker compose
â””â”€â”€ README.md                      # ğŸ“– This file
```

## ğŸ“Š Káº¿t quáº£ vÃ  TÃ­nh nÄƒng

### Pipeline Output
Sau khi cháº¡y `json_export_pipeline.py`, báº¡n sáº½ cÃ³:

1. **export-TIMESTAMP.json**: Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch vÃ  standardized vá»›i cÃ¡c trÆ°á»ng:
   - `source`: Nguá»“n dá»¯ liá»‡u (careerlink, joboko, topcv)
   - `job_title_clean`: TÃªn cÃ´ng viá»‡c Ä‘Ã£ chuáº©n hÃ³a
   - `company_name`: TÃªn cÃ´ng ty
   - `location_clean`, `city`, `country`: Äá»‹a Ä‘iá»ƒm Ä‘Ã£ chuáº©n hÃ³a
   - `salary_min`, `salary_max`, `salary_currency`: Má»©c lÆ°Æ¡ng
   - `skills`: Ká»¹ nÄƒng yÃªu cáº§u
   - `experience`: Sá»‘ nÄƒm kinh nghiá»‡m
   - `industry`, `job_type`, `job_description`: ThÃ´ng tin chi tiáº¿t
   - VÃ  nhiá»u trÆ°á»ng khÃ¡c...

2. **matching_report-TIMESTAMP.json**: Káº¿t quáº£ Schema & Data Matching:
   - **Schema Analysis**:
     - Schema compatibility giá»¯a cÃ¡c nguá»“n
     - Unified schema definition
     - Field coverage analysis
   - **Data Matching**:
     - Duplicate records & groups
     - Similar records analysis
     - Entity resolution (companies, job titles)

3. **pipeline_summary.json**: TÃ³m táº¯t káº¿t quáº£ cháº¡y pipeline:
   - Pipeline info (version, run date)
   - Data sources statistics
   - Schema matching metrics
   - Data matching metrics
   - Files generated

### Quy trÃ¬nh Pipeline

```
1. Load Data (DataFrame in memory)
   â†“
2. Clean & Standardize â¬…ï¸ LÃ€M TRÆ¯á»šC (Pandas operations - NO MongoDB)
   - Normalize text, locations, salaries
   - Extract structured data (experience, skills)
   - Standardize column names
   - Táº¡o standard columns
   â†“
3. Schema Matching (Pandas operations - NO MongoDB)
   - Detect schema tá»« cleaned data
   - So sÃ¡nh schema Ä‘Ã£ standardized
   - Táº¡o unified schema
   - Validate compatibility
   â†“
4. Data Matching (Pandas operations - NO MongoDB)
   - TÃ¬m duplicates trÃªn cleaned data (chÃ­nh xÃ¡c hÆ¡n)
   - Entity resolution (companies, job titles)
   - Similarity analysis vá»›i normalized values
   â†“
5. Combine Data
   - Merge táº¥t cáº£ sources
   - Remove unnecessary columns
   â†“
6. Export to export-{timestamp}.json
```

**LÆ°u Ã½ quan trá»ng:**
- âœ… **Clean & Standardize Ä‘Æ°á»£c lÃ m TRÆ¯á»šC** Ä‘á»ƒ normalize dá»¯ liá»‡u
- âœ… Schema Matching vÃ  Data Matching cháº¡y trÃªn **cleaned data** (sau clean)
- âœ… Sá»­ dá»¥ng Pandas operations, **KHÃ”NG dÃ¹ng MongoDB**
- âœ… Data Matching chÃ­nh xÃ¡c hÆ¡n vá»›i dá»¯ liá»‡u Ä‘Ã£ normalized
- âœ… KhÃ´ng cáº§n map columns thá»§ cÃ´ng (Ä‘Ã£ cÃ³ standard columns)

### TÃ­nh nÄƒng Pipeline

**Schema Matching:**
- âœ… Tá»± Ä‘á»™ng detect schema tá»« cleaned data
- âœ… So sÃ¡nh tÆ°Æ¡ng thÃ­ch schema giá»¯a cÃ¡c nguá»“n (Ä‘Ã£ standardized)
- âœ… Táº¡o unified schema definition
- âœ… Field coverage analysis

**Data Matching:**
- âœ… Duplicate detection (exact & fuzzy matching)
- âœ… Similarity analysis vá»›i Levenshtein distance
- âœ… Entity resolution cho companies vÃ  job titles
- âœ… Automatic column mapping tá»« raw â†’ standard

**Data Cleaning:**
- âœ… Text normalization (remove special chars, normalize unicode)
- âœ… Location extraction (city, province, country)
- âœ… Salary extraction vÃ  conversion (VND, USD)
- âœ… Experience extraction tá»« text
- âœ… Skills extraction vÃ  normalization


## ğŸ” Schema Matching & Data Matching

### Schema Matching
- **Má»¥c Ä‘Ã­ch**: PhÃ¡t hiá»‡n vÃ  so sÃ¡nh schema giá»¯a cÃ¡c nguá»“n dá»¯ liá»‡u
- **Input**: Cleaned & standardized data
- **Output**:
  - Schema compatibility score
  - Unified schema definition
  - Field coverage analysis
- **Technology**: Pandas operations, Levenshtein distance cho fuzzy matching
- **Lá»£i Ã­ch**: Schema Ä‘Ã£ standardized nÃªn so sÃ¡nh dá»… dÃ ng vÃ  chÃ­nh xÃ¡c hÆ¡n

### Data Matching
- **Má»¥c Ä‘Ã­ch**: TÃ¬m duplicates vÃ  entity resolution
- **Input**: Cleaned & standardized data (Ä‘Ã£ cÃ³ standard columns)
- **Output**:
  - Duplicate records & groups
  - Similar records analysis
  - Entity resolution (unique companies, job titles)
- **Technology**: Pandas operations, Levenshtein ratio cho similarity
- **Features**:
  - âœ… KhÃ´ng cáº§n map columns (Ä‘Ã£ cÃ³ standard columns)
  - âœ… Fuzzy matching chÃ­nh xÃ¡c hÆ¡n vá»›i normalized values
  - âœ… Entity deduplication hiá»‡u quáº£ hÆ¡n
- **Lá»£i Ã­ch**: Matching chÃ­nh xÃ¡c hÆ¡n vÃ¬ values Ä‘Ã£ normalized (vÃ­ dá»¥: "HÃ  Ná»™i" â†’ "Ha Noi")

### LÃ½ do thá»© tá»± hiá»‡n táº¡i (Clean â†’ Schema Match â†’ Data Match)
Pipeline cháº¡y **Clean & Standardize TRÆ¯á»šC** Schema Matching vÃ  Data Matching:
- âœ… **Data Matching chÃ­nh xÃ¡c hÆ¡n**: Values Ä‘Ã£ normalized â†’ matching tá»‘t hÆ¡n
- âœ… **KhÃ´ng cáº§n map columns**: ÄÃ£ cÃ³ standard columns (job_title_clean, company_name, etc.)
- âœ… **Code Ä‘Æ¡n giáº£n hÆ¡n**: KhÃ´ng cáº§n logic map columns thá»§ cÃ´ng
- âœ… **Schema Matching dá»… dÃ ng**: So sÃ¡nh schema Ä‘Ã£ standardized
- âœ… **Performance tá»‘t**: KhÃ´ng cáº§n xá»­ lÃ½ nhiá»u láº§n

## ğŸ¯ Use Cases

### 1. PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng viá»‡c lÃ m
- Xem xu hÆ°á»›ng tuyá»ƒn dá»¥ng theo ngÃ nh, Ä‘á»‹a Ä‘iá»ƒm
- So sÃ¡nh má»©c lÆ°Æ¡ng giá»¯a cÃ¡c vá»‹ trÃ­
- PhÃ¢n tÃ­ch ká»¹ nÄƒng Ä‘Æ°á»£c yÃªu cáº§u nhiá»u nháº¥t

### 2. Dá»± Ä‘oÃ¡n lÆ°Æ¡ng
- API `/api/analytics/salary-prediction` cung cáº¥p dá»± Ä‘oÃ¡n lÆ°Æ¡ng dá»±a trÃªn:
  - TÃªn cÃ´ng viá»‡c
  - Äá»‹a Ä‘iá»ƒm
  - Kinh nghiá»‡m
  - NgÃ nh nghá»

### 3. TÃ¬m kiáº¿m vÃ  lá»c cÃ´ng viá»‡c
- API `/api/jobs` cho phÃ©p filter theo nhiá»u tiÃªu chÃ­
- Dashboard cung cáº¥p UI trá»±c quan Ä‘á»ƒ explore data

### 4. Export vÃ  share data
- Dá»¯ liá»‡u JSON dá»… dÃ ng chia sáº»
- Dashboard cÃ³ chá»©c nÄƒng download CSV/JSON

## ğŸ”§ Customization

### ThÃªm nguá»“n dá»¯ liá»‡u má»›i
1. ThÃªm file JSON vÃ o thÆ° má»¥c `data/`
2. Cáº­p nháº­t `config/config.yaml`
3. (Náº¿u cáº§n) ThÃªm cleaning method trong `src/etl/data_cleaner.py`

### ThÃªm phÃ¢n tÃ­ch má»›i
1. Táº¡o module má»›i trong `src/analytics/`
2. Import vÃ  sá»­ dá»¥ng trong `json_export_pipeline.py`

## ğŸ“ˆ Performance

- **Processing Speed**: 
  - Load Data: ~1-2 giÃ¢y
  - Schema Matching: ~2-3 giÃ¢y
  - Data Matching: ~5-10 giÃ¢y (depends on dataset size)
  - Clean & Standardize: ~5-10 giÃ¢y
  - **Total**: ~15-30 giÃ¢y cho 25,000+ records
- **File Size**: 
  - Export data: ~10-20 MB
  - Matching report: ~2-5 MB
  - Pipeline summary: ~50-100 KB
- **Memory Usage**: ~500MB - 1GB cho dataset 25K records

## â“ FAQ

**Q: Táº¡i sao khÃ´ng dÃ¹ng database?**
A: Äá»ƒ Ä‘Æ¡n giáº£n hÃ³a dá»± Ã¡n. File JSON Ä‘á»§ cho dataset cá»¡ nhá»-trung bÃ¬nh (<100K records), dá»… chia sáº» vÃ  khÃ´ng cáº§n setup database.

**Q: LÃ m sao Ä‘á»ƒ update dá»¯ liá»‡u?**
A: Cháº¡y láº¡i `python json_export_pipeline.py`. Dashboard vÃ  API sáº½ tá»± Ä‘á»™ng load file JSON má»›i nháº¥t.

**Q: Schema Matching vÃ  Data Matching cÃ³ sá»­ dá»¥ng MongoDB khÃ´ng?**
A: **KHÃ”NG**. Cáº£ Schema Matching vÃ  Data Matching Ä‘á»u cháº¡y trÃªn Pandas DataFrames trong memory, khÃ´ng sá»­ dá»¥ng MongoDB. MongoDB chá»‰ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ (náº¿u dÃ¹ng database pipeline), khÃ´ng pháº£i trong json_export_pipeline.

**Q: Táº¡i sao Clean & Standardize lÃ m TRÆ¯á»šC Schema Matching vÃ  Data Matching?**
A: Pipeline hiá»‡n táº¡i lÃ m Clean TRÆ¯á»šC vÃ¬:
- âœ… **Data Matching chÃ­nh xÃ¡c hÆ¡n**: Values Ä‘Ã£ normalized â†’ "HÃ  Ná»™i", "Ha Noi", "HN" â†’ "Ha Noi" (match Ä‘Æ°á»£c)
- âœ… **KhÃ´ng cáº§n map columns**: ÄÃ£ cÃ³ standard columns sáºµn
- âœ… **Code Ä‘Æ¡n giáº£n**: KhÃ´ng cáº§n logic map columns thá»§ cÃ´ng
- âœ… **Schema Matching dá»… dÃ ng**: So sÃ¡nh schema Ä‘Ã£ standardized

**Q: CÃ³ thá»ƒ Ä‘á»•i thá»© tá»± khÃ´ng?**
A: CÃ³ thá»ƒ, nhÆ°ng khÃ´ng khuyáº¿n nghá»‹:
- Náº¿u lÃ m Matching trÆ°á»›c Clean: cáº§n map columns thá»§ cÃ´ng, matching kÃ©m chÃ­nh xÃ¡c
- Clean trÆ°á»›c Matching (hiá»‡n táº¡i): Matching chÃ­nh xÃ¡c hÆ¡n, code Ä‘Æ¡n giáº£n hÆ¡n

**Q: CÃ³ thá»ƒ dÃ¹ng vá»›i dá»¯ liá»‡u lá»›n hÆ¡n khÃ´ng?**
A: Vá»›i >100K records, nÃªn cÃ¢n nháº¯c dÃ¹ng database (PostgreSQL) hoáº·c Parquet files Ä‘á»ƒ tá»‘i Æ°u performance.

**Q: LÃ m sao Ä‘á»ƒ deploy lÃªn production?**
A: 
1. Sá»­ dá»¥ng Docker: `docker-compose up -d`
2. Hoáº·c deploy trÃªn cloud (Heroku, AWS, GCP, Azure)
3. Setup cron job Ä‘á»ƒ cháº¡y pipeline Ä‘á»‹nh ká»³

**Q: File cÅ© trong output/ cÃ³ bá»‹ ghi Ä‘Ã¨ khÃ´ng?**
A: KhÃ´ng! Má»—i láº§n cháº¡y pipeline sáº½ táº¡o file má»›i vá»›i timestamp khÃ¡c nhau.

## ğŸ”„ Workflow Chi tiáº¿t

### Step-by-Step Pipeline

1. **Load Data** (1-2s)
   - Äá»c JSON files tá»« `data/`
   - Convert to pandas DataFrames
   - Total: ~6,000-25,000 records

2. **Clean & Standardize**(5-10s)
   - Clean text (normalize, remove special chars)
   - Extract structured data (salary, experience)
   - Standardize column names
   - Táº¡o standard columns (job_title_clean, company_name, location_clean, etc.)
   - Output: Standardized DataFrames

3. **Schema Matching** (2-3s)
   - Detect schema tá»« cleaned data
   - So sÃ¡nh schema Ä‘Ã£ standardized
   - Calculate compatibility score
   - Output: Schema analysis report

4. **Data Matching** (5-10s)
   - Find exact duplicates (chÃ­nh xÃ¡c hÆ¡n vá»›i normalized data)
   - Find similar records (fuzzy matching vá»›i normalized values)
   - Entity resolution (companies, job titles)
   - Output: Matching report

5. **Combine Data** (1-2s)
   - Concatenate all sources
   - Remove unnecessary columns
   - Add source identifiers
   - Output: Combined DataFrame

6. **Export** (1-2s)
   - Convert DataFrame â†’ JSON
   - Write to `output/export-TIMESTAMP.json`
   - Write matching report
   - Write pipeline summary

## ğŸ“„ License

MIT License

## ğŸ“ Contact

- **Author**: Nguyá»…n Thuá»³ DÆ°Æ¡ng
- **Email**: Duong.NT252022M@sis.hust.edu.vn

---

## ğŸ“š Tech Stack References

- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Plotly Documentation](https://plotly.com/python/)

---

**âœ¨ Dá»± Ã¡n phÃ¢n tÃ­ch thá»‹ trÆ°á»ng viá»‡c lÃ m - PhiÃªn báº£n Ä‘Æ¡n giáº£n vá»›i JSON**

*Last updated: 2025*
